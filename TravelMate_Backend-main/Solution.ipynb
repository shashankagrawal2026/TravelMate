{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m venv hackathon\n",
    "# !source hackathon/bin/activate\n",
    "# %pip install jupyter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m ipykernel install --user --name=hackathon --display-name \"Python (hackathon)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nx-arangodb in ./hackathon/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas in ./hackathon/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in ./hackathon/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: python-dotenv in ./hackathon/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: flask in ./hackathon/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: flask-cors in ./hackathon/lib/python3.10/site-packages (5.0.1)\n",
      "Requirement already satisfied: adbnx-adapter~=5.0.5 in ./hackathon/lib/python3.10/site-packages (from nx-arangodb) (5.0.6)\n",
      "Requirement already satisfied: networkx<=3.4,>=3.0 in ./hackathon/lib/python3.10/site-packages (from nx-arangodb) (3.4)\n",
      "Requirement already satisfied: phenolrs~=0.5 in ./hackathon/lib/python3.10/site-packages (from nx-arangodb) (0.5.9)\n",
      "Requirement already satisfied: python-arango~=8.1 in ./hackathon/lib/python3.10/site-packages (from nx-arangodb) (8.1.6)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./hackathon/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./hackathon/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./hackathon/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./hackathon/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=8 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./hackathon/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: click>=8.1.3 in ./hackathon/lib/python3.10/site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in ./hackathon/lib/python3.10/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: blinker>=1.9 in ./hackathon/lib/python3.10/site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./hackathon/lib/python3.10/site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in ./hackathon/lib/python3.10/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in ./hackathon/lib/python3.10/site-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=45 in ./hackathon/lib/python3.10/site-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (59.6.0)\n",
      "Requirement already satisfied: rich>=12.5.1 in ./hackathon/lib/python3.10/site-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./hackathon/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: PyJWT in ./hackathon/lib/python3.10/site-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
      "Requirement already satisfied: importlib_metadata>=4.7.1 in ./hackathon/lib/python3.10/site-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
      "Requirement already satisfied: requests_toolbelt in ./hackathon/lib/python3.10/site-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./hackathon/lib/python3.10/site-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./hackathon/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./hackathon/lib/python3.10/site-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./hackathon/lib/python3.10/site-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./hackathon/lib/python3.10/site-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./hackathon/lib/python3.10/site-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./hackathon/lib/python3.10/site-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./hackathon/lib/python3.10/site-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in ./hackathon/lib/python3.10/site-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./hackathon/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in ./hackathon/lib/python3.10/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-community in ./hackathon/lib/python3.10/site-packages (0.3.19)\n",
      "Requirement already satisfied: langgraph in ./hackathon/lib/python3.10/site-packages (0.3.5)\n",
      "Requirement already satisfied: requests<3,>=2 in ./hackathon/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./hackathon/lib/python3.10/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./hackathon/lib/python3.10/site-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./hackathon/lib/python3.10/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./hackathon/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./hackathon/lib/python3.10/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in ./hackathon/lib/python3.10/site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./hackathon/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./hackathon/lib/python3.10/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./hackathon/lib/python3.10/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./hackathon/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./hackathon/lib/python3.10/site-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./hackathon/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./hackathon/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in ./hackathon/lib/python3.10/site-packages (from langgraph) (0.1.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in ./hackathon/lib/python3.10/site-packages (from langgraph) (2.0.18)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in ./hackathon/lib/python3.10/site-packages (from langgraph) (0.1.55)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./hackathon/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./hackathon/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./hackathon/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./hackathon/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./hackathon/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./hackathon/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in ./hackathon/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./hackathon/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./hackathon/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./hackathon/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./hackathon/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./hackathon/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./hackathon/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./hackathon/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./hackathon/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./hackathon/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./hackathon/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./hackathon/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./hackathon/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./hackathon/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: anyio in ./hackathon/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.8.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./hackathon/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./hackathon/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./hackathon/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./hackathon/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./hackathon/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nx-arangodb pandas matplotlib python-dotenv flask flask-cors\n",
    "%pip install --upgrade langchain langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 10 03:08:43 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P0              N/A /  60W |      8MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1982      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Nov_18_09:45:30_PST_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.119\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\n"
     ]
    }
   ],
   "source": [
    "# Check if there's an NVIDIA GPU\n",
    "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
    "\n",
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
      "Requirement already satisfied: nx-cugraph-cu12 in ./hackathon/lib/python3.10/site-packages (25.2.0)\n",
      "Requirement already satisfied: pylibcugraph-cu12==25.2.* in ./hackathon/lib/python3.10/site-packages (from nx-cugraph-cu12) (25.2.0)\n",
      "Requirement already satisfied: numpy<3.0a0,>=1.23 in ./hackathon/lib/python3.10/site-packages (from nx-cugraph-cu12) (1.26.4)\n",
      "Requirement already satisfied: cupy-cuda12x>=12.0.0 in ./hackathon/lib/python3.10/site-packages (from nx-cugraph-cu12) (13.4.0)\n",
      "Requirement already satisfied: networkx>=3.2 in ./hackathon/lib/python3.10/site-packages (from nx-cugraph-cu12) (3.4)\n",
      "Requirement already satisfied: pylibraft-cu12==25.2.* in ./hackathon/lib/python3.10/site-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
      "Requirement already satisfied: rmm-cu12==25.2.* in ./hackathon/lib/python3.10/site-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
      "Requirement already satisfied: libcugraph-cu12==25.2.* in ./hackathon/lib/python3.10/site-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
      "Requirement already satisfied: libraft-cu12==25.2.* in ./hackathon/lib/python3.10/site-packages (from libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
      "Requirement already satisfied: cuda-python<13.0a0,>=12.6.2 in ./hackathon/lib/python3.10/site-packages (from pylibraft-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.8.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in ./hackathon/lib/python3.10/site-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12 in ./hackathon/lib/python3.10/site-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12 in ./hackathon/lib/python3.10/site-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12 in ./hackathon/lib/python3.10/site-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.8.93)\n",
      "Requirement already satisfied: fastrlock>=0.5 in ./hackathon/lib/python3.10/site-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
      "Requirement already satisfied: cuda-bindings~=12.8.0 in ./hackathon/lib/python3.10/site-packages (from cuda-python<13.0a0,>=12.6.2->pylibraft-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.8.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./hackathon/lib/python3.10/site-packages (from nvidia-cusolver-cu12->libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.8.93)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install nx-cugraph via pip\n",
    "# Note: Only enable this installation if the step above is working!\n",
    "\n",
    "%pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:09:29 +0530] [INFO]: NetworkX-cuGraph is available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required modules\n",
    "\n",
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "\n",
    "from arango import ArangoClient\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib.parse\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "import threading\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------WIKIPEDIA API----------------------------------------------------------------------\n",
    "\n",
    "def get_wikipedia_info(name):\n",
    "    # Step 1: Construct the API URL\n",
    "    search_title = \"https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch=\" + \\\n",
    "        urllib.parse.quote(name) + \\\n",
    "        \"&format=json&origin=*\"\n",
    "    search_title_response = requests.get(search_title)\n",
    "    if search_title_response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Failed to fetch search results. Received: {search_title_response.status_code} {search_title_response.reason}\"\n",
    "        )\n",
    "    \n",
    "    search_title_data = search_title_response.json()\n",
    "    if len(search_title_data[\"query\"][\"search\"]) == 0:\n",
    "        return \"No information found on Wikipedia\"\n",
    "    \n",
    "    title = search_title_data[\"query\"][\"search\"][0][\"title\"]\n",
    "\n",
    "    search_url = \"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&titles=\" + \\\n",
    "        urllib.parse.quote(title) + \\\n",
    "        \"&explaintext=1&origin=*\"\n",
    "    \n",
    "    search_response = requests.get(search_url)\n",
    "    if search_response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Failed to fetch search results. Received: {search_response.status_code} {search_response.reason}\"\n",
    "        )\n",
    "\n",
    "    # Parse the JSON response\n",
    "    search_data = search_response.json()\n",
    "\n",
    "    data = search_data['query']['pages']\n",
    "    page_number = list(data.keys())[0]\n",
    "    extracted_text = data[page_number]['extract']\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------MAPS API----------------------------------------------------------------------\n",
    "\n",
    "def get_maps_places(location, search_text=\"Most Popular places in \"):\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    # Step 1: Construct the API URL for Google Maps Places API\n",
    "    search_query = search_text + location\n",
    "    search_url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?query=\" + \\\n",
    "        urllib.parse.quote(search_query) + \\\n",
    "        f\"&radius=20000&key={api_key}\"  # Replace with your actual API key\n",
    "    \n",
    "    search_response = requests.get(search_url)\n",
    "    if search_response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Failed to fetch search results. Received: {search_response.status_code} {search_response.reason}\"\n",
    "        )\n",
    "\n",
    "    # Parse the JSON response\n",
    "    search_data = search_response.json()\n",
    "    return search_data[\"results\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------Wiki details of Maps recommended places Function-------------------------------------------------------\n",
    "\n",
    "def get_wiki_desc_for_places(destination_location, sz = 2):\n",
    "    places = get_maps_places(destination_location, \"Most Popular places in \")\n",
    "    place_descriptors = []\n",
    "    \n",
    "    for i in range(min(sz, len(places))):\n",
    "        description = get_wikipedia_info(places[i][\"name\"])\n",
    "\n",
    "        place_descriptor = {\n",
    "            \"place\": places[i][\"name\"],\n",
    "            \"description\": description,\n",
    "            \"destination\": destination_location\n",
    "        }\n",
    "        place_descriptors.append(place_descriptor)\n",
    "    \n",
    "    return place_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------GEMINI API----------------------------------------------------------------------\n",
    "def call_gemini_api(prompt):\n",
    "    \"\"\"\n",
    "    Call the Gemini API with the given prompt.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"No Gemini API key provided. Set the GEMINI_API_KEY environment variable\")\n",
    "    \n",
    "    url = \"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro:generateContent\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"key\": api_key\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"generationConfig\": {\n",
    "            \"temperature\": 0.2,\n",
    "            \"topP\": 0.8,\n",
    "            \"topK\": 40,\n",
    "            \"maxOutputTokens\": 8192\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, params=params, json=data)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to call Gemini API. Received: {response.status_code} {response.reason} - {response.text}\")\n",
    "    \n",
    "    response_json = response.json()\n",
    "    \n",
    "    # Extract the text from the response\n",
    "    if \"candidates\" in response_json and len(response_json[\"candidates\"]) > 0:\n",
    "        if \"content\" in response_json[\"candidates\"][0] and \"parts\" in response_json[\"candidates\"][0][\"content\"]:\n",
    "            return response_json[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    \n",
    "    return \"No response generated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Knowledge Extraction with Gemini----------------------------------------------------------------------\n",
    "def extract_knowledge_from_gemini(destination):\n",
    "    \"\"\"\n",
    "    Extract structured knowledge about a destination using Gemini API.\n",
    "    Returns a list of dictionaries with relationship triples.\n",
    "    \"\"\"\n",
    "    # First, get descriptive information about the places\n",
    "    place_descriptors = get_wiki_desc_for_places(destination)\n",
    "    \n",
    "    # Now ask Gemini to structure this into a TSV format\n",
    "    extraction_prompt = f\"\"\"Based on the following information about tourist attractions in {destination}, extract a highly detailed knowledge graph in TSV format that captures diverse relationships between attractions, their history, significance, and travel-related insights.\n",
    "    {place_descriptors}\n",
    "\n",
    "    Format:\n",
    "    Create a TSV with the following columns:\n",
    "\n",
    "    Node_1: The name of the entity (e.g., attraction, person, event, historical figure, location, year).\n",
    "    Relation: The relationship between Node_1 and Node_2 (e.g., LOCATED_IN, BUILT_IN, KNOWN_FOR, DESIGNED_BY, INFLUENCED_BY, HAS_EVENT, CULTURAL_IMPORTANCE, RECOMMENDED_ACTIVITY).\n",
    "    Node_2: The entity that Node_1 is related to.\n",
    "    Node_1_Type: The type of Node_1 (e.g., Attraction, Landmark, Event, Architect, Year, Culture, TravelTip).\n",
    "    Node_2_Type: The type of Node_2 (e.g., Location, AttractionType, Architect, Year, CulturalAspect, RecommendedActivity).\n",
    "    Attributes: A JSON string with additional information (e.g., opening hours, ticket price, notable facts, visiting tips).\n",
    "    Guidelines:\n",
    "\n",
    "    Extract at least 8 relationships per attraction to create a dense knowledge graph.\n",
    "    Include core travel-related information such as:\n",
    "    Best time to visit (e.g., \"Eiffel Tower\" → BEST_VISITED_IN → \"Evening\")\n",
    "    Famous events held there (e.g., \"Sydney Opera House\" → HOSTS_EVENT → \"Vivid Sydney Festival\")\n",
    "    Recommended activities (e.g., \"Grand Canyon\" → RECOMMENDED_ACTIVITY → \"Hiking\")\n",
    "    Nearby attractions (e.g., \"Louvre Museum\" → NEARBY_ATTRACTION → \"Seine River\")\n",
    "    Historical significance (e.g., \"Colosseum\" → HISTORIC_IMPORTANCE → \"Gladiator battles\")\n",
    "    Influences (e.g., \"Taj Mahal\" → INFLUENCED_BY → \"Mughal Architecture\")\n",
    "    Travel insights (e.g., \"Machu Picchu\" → TRAVEL_TIP → \"Get tickets in advance\")\n",
    "    Ensure each attraction is connected to broader travel concepts, such as:\n",
    "    The country it belongs to\n",
    "    Related UNESCO heritage status (if applicable)\n",
    "    Any notable designers, rulers, or figures associated with it\n",
    "    Instructions for Output:\n",
    "\n",
    "    Just return the TSV content without markdown formatting or extra text.\n",
    "    The first line should be the header row.\"\"\"\n",
    "\n",
    "    tsv_content = call_gemini_api(extraction_prompt)\n",
    "    \n",
    "    # Clean up the response to ensure it's just TSV content\n",
    "    if \"```\" in tsv_content:\n",
    "        # Extract content between triple backticks if present\n",
    "        tsv_content = tsv_content.split(\"```\")[1].strip()\n",
    "        if tsv_content.startswith(\"tsv\"):\n",
    "            tsv_content = tsv_content[3:].strip()\n",
    "    \n",
    "    return tsv_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Knowledge Pandas Dataframe----------------------------------------------------------------------\n",
    "\n",
    "def create_travel_knowledge_dataframe(destination_location: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a DataFrame containing travel knowledge about places in the specified destination\n",
    "    using the Gemini API.\n",
    "    \"\"\"\n",
    "    print(f\"Creating travel knowledge graph for {destination_location}...\")\n",
    "    \n",
    "    # Get TSV content from Gemini\n",
    "    tsv_content = extract_knowledge_from_gemini(destination_location)\n",
    "    \n",
    "    # Convert TSV string to DataFrame\n",
    "    df = pd.read_csv(io.StringIO(tsv_content), sep='\\t')\n",
    "    \n",
    "    # Handle any necessary data cleaning\n",
    "    if 'Attributes' in df.columns:\n",
    "        # Ensure Attributes is a valid JSON string\n",
    "        df['Attributes'] = df['Attributes'].apply(lambda x: '{}' if pd.isna(x) or x == '' else x)\n",
    "        \n",
    "        # Verify JSON formatting\n",
    "        def ensure_json(attr_str):\n",
    "            try:\n",
    "                # If it's already a JSON object, convert to string\n",
    "                if isinstance(attr_str, dict):\n",
    "                    return json.dumps(attr_str)\n",
    "                # Try to parse as JSON to validate\n",
    "                json.loads(attr_str)\n",
    "                return attr_str\n",
    "            except:\n",
    "                # If not valid JSON, return empty object\n",
    "                return '{}'\n",
    "        \n",
    "        df['Attributes'] = df['Attributes'].apply(ensure_json)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=['Node_1', 'Relation', 'Node_2'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_key(name):\n",
    "    \"\"\"Converts a name into a valid _key for ArangoDB.\"\"\"\n",
    "    name = name.lower().strip()  # Ensure consistent casing and remove trailing spaces\n",
    "    name = re.sub(r'[^a-z0-9_-]', '_', name)  # Replace invalid characters\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Knowledge Graph from Dataframe----------------------------------------------------------------------\n",
    "\n",
    "def generate_knowledge_graph(G, destination):\n",
    "    # Debug statement: Print the number of nodes and edges in the input graph\n",
    "    print(f\"\\nInput graph before modification: {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # destination = \"Varanasi\"  # Change this to any destination you want\n",
    "    df = create_travel_knowledge_dataframe(destination)\n",
    "    \n",
    "    # Display the first few rows of the DataFrame\n",
    "    print(\"\\nSample of the knowledge graph data:\")\n",
    "    print(df.head(2).to_string())\n",
    "    \n",
    "    # Track how many new elements we're adding\n",
    "    nodes_added = 0\n",
    "    edges_added = 0\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Sanitize keys for ArangoDB\n",
    "        node1_key = sanitize_key(row['Node_1'])\n",
    "        node2_key = sanitize_key(row['Node_2'])\n",
    "\n",
    "        # Check if nodes already exist before adding them\n",
    "        if not G.has_node(node1_key):\n",
    "            G.add_node(node1_key, key=node1_key, name=row['Node_1'], type=row['Node_1_Type'])\n",
    "            nodes_added += 1\n",
    "        \n",
    "        if not G.has_node(node2_key):\n",
    "            G.add_node(node2_key, key=node2_key, name=row['Node_2'], type=row['Node_2_Type'])\n",
    "            nodes_added += 1\n",
    "\n",
    "        # Check if edge already exists before adding it\n",
    "        if not G.has_edge(node1_key, node2_key):\n",
    "            G.add_edge(node1_key, node2_key, relation=row['Relation'], attributes=row['Attributes'])\n",
    "            edges_added += 1\n",
    "    \n",
    "    print(f\"\\nAdded {nodes_added} new nodes and {edges_added} new edges\")\n",
    "    print(f\"Output graph after modification: {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Knowledge Graph Plot----------------------------------------------------------------------\n",
    "\n",
    "def plot_knowledge_graph(destination):\n",
    "    G = generate_knowledge_graph(G,destination)\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Define node positions\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    # Draw nodes with labels\n",
    "    nx.draw(G, pos, with_labels=True, node_size=1000, node_color=\"lightblue\", edge_color=\"gray\")\n",
    "\n",
    "    # Draw edge labels (relationship types)\n",
    "    edge_labels = {(u, v): d['relation'] for u, v, d in G.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "    plt.title(\"Knowledge Graph from LLM-Generated Table\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------Gateway to Create KG if not Exists------------------------------------------------------\n",
    "def fetch_or_create_city(city_name, existing_city_names, G):\n",
    "    \"\"\"\n",
    "    Fetches or creates a city in the graph database based on the list of existing city names..\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if city_name in existing_city_names:\n",
    "            print(\"City already exists in the database\")\n",
    "            return G\n",
    "        else:\n",
    "            G = generate_knowledge_graph(G, city_name)\n",
    "            print(\"City created successfully\")\n",
    "            return G\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error executing graph operation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Add Selected key to places object----------------------------------------------------------------------\n",
    "\n",
    "def add_selected_key_to_places(places_google_maps, extracted_list):\n",
    "    \"\"\"\n",
    "    Add 'selected' as a key to Google maps generated list of places.\n",
    "    \n",
    "    Args:\n",
    "        places_google_maps (list): List of places from Google Maps\n",
    "        extracted_list (list): List of selected places\n",
    "        \n",
    "    Returns:\n",
    "        list: Modified places\n",
    "    \"\"\"\n",
    "    modified_places = []\n",
    "    for place in places_google_maps:\n",
    "        if place[\"name\"] in extracted_list:\n",
    "            modified_place = place.copy()\n",
    "            modified_place[\"selected\"] = True\n",
    "            modified_places.append(modified_place)\n",
    "    return modified_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Use User Input to filter places----------------------------------------------------------------------\n",
    "\n",
    "def get_top_k_places(input_data, existing_city_names, G):\n",
    "    \"\"\"\n",
    "    Retrieves the top K places based on the user's input data.\n",
    "\n",
    "    Args:\n",
    "        input_data (dict): The user's input data containing destination, budget, interests, etc.\n",
    "        existing_city_names (list): List of existing city names in the database\n",
    "        G (nx.Graph): NetworkX graph representing the knowledge graph\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of modified places recommended for the user.\n",
    "    \"\"\"\n",
    "    # Check if the city exists in the database, and the Knowledge Graph has substantial knowledge about it.\n",
    "    G = fetch_or_create_city(input_data[\"destination\"], existing_city_names, G)\n",
    "\n",
    "    # Fetch all places based on the city, country, state.\n",
    "    places_google_maps = get_maps_places(input_data[\"destination\"], \"Most Popular places in \")\n",
    "    sz = len(places_google_maps)\n",
    "    places_ext = []\n",
    "    results_retrieved = []\n",
    "\n",
    "    for i in range(sz):\n",
    "        place_name = places_google_maps[i][\"name\"].replace('\"', '')\n",
    "        place_key = sanitize_key(place_name)  # Use sanitized key\n",
    "        print(place_key)\n",
    "        places_ext.append(place_name)\n",
    "\n",
    "        # For nxadb graphs, use this approach\n",
    "        try:\n",
    "            # Try to get node data - this will raise an exception if the node doesn't exist\n",
    "            node_data = G.nodes[place_key]\n",
    "            print(f\"Found node {place_key} in graph\")\n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(f\"Node {place_key} not found in graph: {str(e)}\")\n",
    "            results_retrieved.append(f'Node \"{place_name}\" was not found in the knowledge graph.')\n",
    "            continue\n",
    "        # Query the graph for relationships\n",
    "        try:\n",
    "            for path_length in range(1, 4):\n",
    "                try:\n",
    "                    for node in nx.single_source_shortest_path_length(G, place_key, cutoff=path_length):\n",
    "                        if node != place_key:\n",
    "                            try:\n",
    "                                path = nx.shortest_path(G, place_key, node)\n",
    "                                \n",
    "                                relationships = []\n",
    "                                for j in range(len(path) - 1):\n",
    "                                    edge_data = G.get_edge_data(path[j], path[j+1])\n",
    "                                    if edge_data and 'relation' in edge_data:\n",
    "                                        relationships.append(edge_data['relation'])\n",
    "                                \n",
    "                                start_node_type = G.nodes.get(place_key, {}).get('type', 'unknown type')\n",
    "                                end_node_name = G.nodes.get(node, {}).get('name', 'unknown')\n",
    "                                end_node_type = G.nodes.get(node, {}).get('type', 'unknown type')\n",
    "\n",
    "                                sentence = (f'Node \"{place_name}, a {start_node_type}\" is connected to '\n",
    "                                            f'Node \"{end_node_name}, a {end_node_type}\" by the '\n",
    "                                            f'relationships: \"{\", \".join(relationships)}\".')\n",
    "                                print(sentence)\n",
    "                                results_retrieved.append(sentence)\n",
    "                            except nx.NetworkXNoPath:\n",
    "                                continue\n",
    "                except nx.NodeNotFound:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing place '{place_name}': {str(e)}\")\n",
    "            results_retrieved.append(f'Error processing relationships for \"{place_name}\": {str(e)}')\n",
    "\n",
    "    if not results_retrieved:\n",
    "        results_retrieved.append(\"No relationship data could be retrieved from the knowledge graph for the given places.\")\n",
    "\n",
    "    retriever = f\"\"\"You are given a list of places and related details extracted from a Knowledge Graph. Your task is to recommend specific places based on the user's destination, budget, and interests. \n",
    "                    Filter the relevant places from the data and return a JSON list containing only the exact names of the places, ensuring that the recommendations align with the user's preferences.\n",
    "\n",
    "                    USER Data:\n",
    "                    Total list of places: {places_ext}\n",
    "                    Source information: {input_data[\"source\"]}\n",
    "                    Destination: {input_data[\"destination\"]}\n",
    "                    Departure Date: {input_data[\"departureDate\"]}\n",
    "                    Return Date: {input_data[\"returnDate\"]}\n",
    "                    Budget: {input_data[\"budget\"]}\n",
    "                    Description of the user's interests: {input_data[\"description\"]}\n",
    "\n",
    "                    Knowledge Graph Data:\n",
    "                    {results_retrieved}\n",
    "                    \"\"\"\n",
    "\n",
    "    try:\n",
    "        json_list_of_places = call_gemini_api(\"You are a travel expert and your task is to recommend specific places based on the user's destination, budget, and interests.\" + retriever)\n",
    "\n",
    "        # Handle potential format issues with the API response\n",
    "        try:\n",
    "            extracted_list_string = json_list_of_places.strip()\n",
    "            \n",
    "            if \"```\" in json_list_of_places:\n",
    "                extracted_list_string = json_list_of_places.split(\"```\")[1].strip()\n",
    "                if extracted_list_string.startswith(\"json\"):\n",
    "                    extracted_list_string = extracted_list_string[4:].strip()\n",
    "            else:\n",
    "                json_pattern = r'\\[\\s*\"[^\"]*\"(?:\\s*,\\s*\"[^\"]*\")*\\s*\\]'\n",
    "                match = re.search(json_pattern, json_list_of_places)\n",
    "                if match:\n",
    "                    extracted_list_string = match.group(0)\n",
    "            \n",
    "            extracted_list = json.loads(extracted_list_string)\n",
    "        except (json.JSONDecodeError, IndexError) as e:\n",
    "            print(f\"Error parsing API response: {str(e)}\")\n",
    "            extracted_list = places_ext  # Fallback to all places if parsing fails\n",
    "\n",
    "        modified_places = add_selected_key_to_places(places_google_maps, extracted_list)\n",
    "        return modified_places, G\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {str(e)}\")\n",
    "        return places_ext, G  # Return all places if API call fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------ Event Planner ------------------------------------------------------ \n",
    "\n",
    "def event_planner(selected_places, user_input):\n",
    "    \"\"\"\n",
    "    Plans a series of events for a group of tourists based on selected places and user input.\n",
    "\n",
    "    Args:\n",
    "        selected_places (str): A string containing the list of places selected by the user.\n",
    "        user_input (str): Additional user input to customize the event plan.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of event plan dictionaries containing details such as place ID, name, \n",
    "              details, timing, famous activities, total duration, recommended transport, \n",
    "              and additional notes.\n",
    "\n",
    "    The function generates a prompt combining the user input and selected places, then uses \n",
    "    an AI text generation function to create a detailed event plan. The response is parsed \n",
    "    into a list of event plans and returned.\n",
    "    \"\"\"\n",
    "\n",
    "    demo = '''[\n",
    "                {\n",
    "                  \"place_id\": 0,\n",
    "                  \"name\": \"Burj Khalifa\",\n",
    "                  \"details\": \"The Burj Khalifa is the tallest building in the world and a major attraction. Start your day early to avoid long queues for the observation deck.\",\n",
    "                  \"timing\": \"9:00 AM to 10:30 AM\"\n",
    "                  \"Famous Activity\": \"Photoshoots\",\n",
    "                  \"total_duration\": \"1-2 hours\",\n",
    "                  \"recommended_transport\": \"Taxi\",\n",
    "                  \"additional_notes\": \"Grab a pair of glasses and a camera. Dress nicely and bring water.\"\n",
    "                },\n",
    "                ...\n",
    "                {\n",
    "                  \"place_id\": 4,\n",
    "                  \"name\": \"Downtown Dubai Park\",\n",
    "                  \"details\": \"Visit another park or green space to enjoy the peaceful environment.\",\n",
    "                  \"timing\": \"1:00 PM to 4:45 PM\",\n",
    "                  \"Famous Activity\": \"Swimming\",\n",
    "                  \"total_duration\": \"4-5 hours\",\n",
    "                  \"recommended_transport\": \"Walking\",\n",
    "                  \"additional_notes\": \"Grab a snack or lunch at Dubai Mall or nearby cafes. Dress comfortably and bring water, especially for outdoor activities.\"\n",
    "                } \n",
    "              ]'''\n",
    "    prompt = (user_input + \"Plan a series of events that will provide a memorable experience for the group. The group is interested in exploring the places listed below.\\n Selected Places:\" + selected_places + \"\\nReturn a smart plan in the form of a 'JSON list of the same structure' containing the events and activities that the group should participate in. Ensure that the plan includes the total number of places to visit, the locations, details, timings, famous activities, total duration, recommended transport, and additional notes.\" + demo)\n",
    "              \n",
    "    response = call_gemini_api(\"You are an event planner and your task is to plan a series of events for a group of tourists.\", prompt)\n",
    "    resp = response.split(\"```\")[1].strip()\n",
    "    event_list = json.loads(resp)\n",
    "    return event_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "PLACES_FILE  = \"existing_places.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load places from JSON\n",
    "def load_places():\n",
    "    with open(PLACES_FILE, \"r\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to add a new place and save\n",
    "def add_place(name):\n",
    "    places = load_places()\n",
    "    if({\"name\": name} not in places):\n",
    "        places.append({\"name\": name})\n",
    "\n",
    "    with open(PLACES_FILE, \"w\") as file:\n",
    "        json.dump(places, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint to get all places\n",
    "@app.route(\"/api/places\", methods=[\"GET\"])\n",
    "def get_places():\n",
    "    with open(PLACES_FILE, \"r\") as file:\n",
    "        places = json.load(file)\n",
    "    city_names = [place[\"name\"] for place in places]  # Extract city names\n",
    "    return jsonify(city_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/api/top-places', methods=['POST'])\n",
    "def top_places():\n",
    "\n",
    "    db = ArangoClient(hosts=\"https://72f3bc481376.arangodb.cloud:8529\").db(username=\"root\", password=\"jznyCFlCYCwMCH5q2wV8\", verify=True)\n",
    "    G = nxadb.Graph(name=\"TravelMate\", db=db)\n",
    "    # existing_city_names = [\"Varanasi\", \"Bombay\", \"Kolkata\"]\n",
    "    places = load_places()\n",
    "    existing_city_names = [place[\"name\"] for place in places]\n",
    "    print(existing_city_names)\n",
    "    \"\"\"\n",
    "    REST API endpoint to get top places based on user data\n",
    "    \"\"\"\n",
    "    # Get user data from request\n",
    "    user_data = request.json\n",
    "    destination_name = user_data['destination']\n",
    "\n",
    "    if not user_data:\n",
    "        return jsonify({\"error\": \"No user data provided\"}), 400\n",
    "    \n",
    "    # Get top places based on user data\n",
    "    places, updated_G = get_top_k_places(user_data, existing_city_names, G)\n",
    "    add_place(destination_name)\n",
    "    G = updated_G\n",
    "    \n",
    "    # Return the places\n",
    "    return jsonify({\"places\": places})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/api/event-planner\", methods=[\"POST\"])\n",
    "def api_event_planner():\n",
    "    \"\"\"Handle event planner requests\"\"\"\n",
    "    data = request.get_json()\n",
    "    \n",
    "    if not data:\n",
    "        return jsonify({\"error\": \"No data provided\"}), 400\n",
    "    \n",
    "    selected_places = data.get(\"selectedPlaces\", \"\")\n",
    "    user_input = data.get(\"userInput\", \"\")\n",
    "    \n",
    "    if not selected_places or not user_input:\n",
    "        return jsonify({\"error\": \"Missing required parameters: selectedPlaces or userInput\"}), 400\n",
    "    \n",
    "    try:\n",
    "        print(selected_places)\n",
    "        print(user_input)\n",
    "        result = event_planner(selected_places, user_input)\n",
    "        print(result)\n",
    "        return jsonify(result), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Flask server running at <a href='http://localhost:5000' target='_blank'>http://localhost:5000</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.20.99.77:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Mar/2025 03:13:26] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [10/Mar/2025 03:13:26] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [10/Mar/2025 03:13:39] \"\u001b[33mGET /api/docs HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [10/Mar/2025 03:13:51] \"\u001b[33mGET /docs HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "def run_flask_app():\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "# Start Flask in a thread\n",
    "flask_thread = threading.Thread(target=run_flask_app)\n",
    "flask_thread.daemon = True\n",
    "flask_thread.start()\n",
    "\n",
    "display(HTML(\"<p>Flask server running at <a href='http://localhost:5000' target='_blank'>http://localhost:5000</a></p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
